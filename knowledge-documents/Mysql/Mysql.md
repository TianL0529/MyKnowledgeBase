### Mysql

当向MySQL发送一个请求的时候，MySQL到底做了些什么：

![image-20210629200301870](D:\Desktop\知识整理\图片\image-20210629200301870.png)

![image-20210711132830593](D:\Desktop\知识整理\图片\image-20210711132830593.png)



* 客户端发送一条查询给服务器；
* 服务器先检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果。否则进入下一阶段；
* 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划；
* MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询；
* 将结果返回给客户端。

**注：**

* 查询缓存：查询缓存往往弊大于利，MySQL 8.0版本直接将缓存的整块功能删掉了；
* 分析器：让MySQL知道需要做什么，分析器先会做“词法分析” --识别关键字，然后是“语法分析” --判断语法规则是否正确；
* 优化器：让MySQL知道怎么做，比如在表里有多个索引的时候，决定使用哪个索引，或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序；
* 执行器：执行语句阶段，先判断权限，然后根据表的引擎定义，去使用这个引擎提供的接口。

**更新流程中涉及到的两个重要日志模块：**事务日志-- *redo log（重做日志）*和undo log（主要用于记录被修改之前的日志，在表信息修改之前会先把数据拷贝到undo log里，当事务进行回滚时可以通过undo log里的日志进行数据还原）、二进制日志--*binlog（归档日志）*。

* redo log、undo log的生成过程
  * 1、修改数据前首先把需要修改的数据从数据表中读取到内存。
  * 2、把需原数据作为历史版本记录到undo log里。
  * 3、把需要变更的数据记录到redo log里。
  * 4、commit或rollback事务，修改表数据。

![img](D:\Desktop\知识整理\图片\v2-64b0220b42fca65e64ced0586f82f135_720w.jpg)

注：WAL：全程为Write-Ahead Logging，即先写日志，再写磁盘。

* redo log（InnodDB引擎特有的日志）：当有一条记录需要更新的时候，InnoDB引擎就会先把记录写道redo log里面，并更新内存，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，往往是在系统比较空闲的时候进行写磁盘。
  * 通常配置一组4个文件，每个文件的大小是1GB；
  * write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头；checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。
  * redo log可以使InnoDB保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 ctash-safe；
  * Binlog有两种模式，statement格式记录的是sql语句，row格式会记录行的内容，记录两条，更新前和更新后都有。

![image-20210711135250367](D:\Desktop\知识整理\图片\image-20210711135250367.png)



binlog（Server层的日志）：binlog日志只能用于归档，没有crash-safe能力。主要用途如下：

* 恢复：利用binlog日志恢复数据库数据
* 复制：主从同步
* 审计：通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入攻击。

常见格式：

|  format   |                        定义                        |              优点              |                             缺点                             |
| :-------: | :------------------------------------------------: | :----------------------------: | :----------------------------------------------------------: |
| statement |                记录的是修改SQL语句                 |  日志文件小，节约IO，提高性能  | 准确性差，对一些系统函数不能准确复制或不能复制，如now()、uuid()等 |
| row(推荐) | 记录的是每行实际数据的变更，记两条，更新前和更新后 | 准确性强，能准确复制数据的变更 |               日志文件大，较大的网络IO和磁盘IO               |
|   mixed   |              statement和row模式的混合              |     准确性强，文件大小适中     |                   有可能发生主从不一致问题                   |

sync_binlog参数：

* 0：表示MySQL不控制binlog的刷新，由文件系统自己控制它的缓存的刷新。这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失。
* n：表示每sync_binlog次事务提交，MySQL调用文件系统的刷新操作将缓存刷下去。最安全的就是sync_binlog=1了，表示每次事务提交，MySQL都会把binlog刷下去，是最安全但是性能损耗最大的设置。这样的话，在数据库所在的主机操作系统损坏或者突然掉电的情况下，系统才有可能丢失1个事务的数据。但是binlog虽然是顺序IO，但是设置sync_binlog=1，多个事务同时提交，同样很大的影响MySQL和IO性能。虽然可以通过group commit的补丁缓解，但是刷新的频率过高对IO的影响也非常大。对于高并发事务的系统来说，“sync_binlog”设置为0和设置为1的系统写入性能差距可能高达5倍甚至更多。所以很多MySQL DBA设置的sync_binlog并不是最安全的1，而是100或者是0。这样牺牲一定的一致性，可以获得更高的并发和性能。





redo log和binlog的区别：

* redo log是InnoDB引擎特有的； binlog是MySQL的Server层实现的，所有引擎都可以使用；
* redo log是物理日志，记录的是“在某个数据页上做了什么修改”； binlig是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1；
* redo log是循环写的，空间固定会用完； binlog是可以追加写入的。”追加写“是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志；

两个日志的写入流程，以undate语句为例：

* 1.执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
* 2.执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
* 3.引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。
* 4.执行器生成这个操作的binlog，并把binlog写入磁盘。
* 5.执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

如下图，浅色狂表示InnoDB内部执行的，深色框表示是在执行器中执行的。

![image-20210711140713410](D:\Desktop\知识整理\图片\image-20210711140713410.png)

两阶段提交
1 prepare阶段 2 写binlog 3 commit
当在2之前崩溃时
重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。
当在3之前崩溃
重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog 。





事务：事务内的语句，要么全部执行成功，要么全部执行失败。

**事务日志**：

​		事务日志可以帮助提高事务的效率。使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修该行为记录到持久在硬盘上的事务日志中，而不是每次都将修改的数据本身持久到磁盘。事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。事务日志持久以后，内存中被修改的数据在后台可以慢慢地刷回到磁盘。我们通常称之为预写日志（Write-Ahead Logging），修改数据需要写两次磁盘。

​	如果数据的修改已经记录到事务日志并持久化，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。具体的恢复方式则视存储引擎而定。

**ACID：**

* 原子性（atomicity）：一个事物必须被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作，这就是事物的原子性。
* 一致性（consisitency）：数据库总是从一个一致性的状态转到另外一个一致性的状态。
* 隔离性（isolation）：通常来说，一个事物所做的修改在最终提交以前，对其他事务是不可见的。
* 持久性（durability）：一旦事务提交，则其所做的修改就会永久保存到数据库中。此时计时系统崩溃，修改的数据也不会丢失。

**隔离级别：**

* **read uncommitted（未提交读）**：事务中的修改，即使没有提交，对其他事务也是可见的。事务可以读取未提交的数据，这也被称为脏读（Dirty Read）。
* **read committed（提交读）**：大部分数据库系统的默认隔离级别都是 read committed（但MySql不是）。一个事务从开始知道提交之前，所做的任何修改对其他事务都是不可见的。这个级别有时候也叫做不可重复读（nonrepeatable read），因为两次执行同样的查询，可能会得到不一样的结果。
* **repeatable read（可重复读）**：解决了脏读的问题。该级别保证了在同一个事务中多次读取同样记录的结果是一致的。但理论上，可重复读隔离级别还是无法解决幻读（Phantom Read）的问题。幻读就是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行（Phantom Row）。 可重复度时MySql的默认事务隔离级别。
* **serializable（可串行化）**：是最高的隔离级别。它通过强制事务串行执行，避免了前面说的幻读的问题。serializable会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用得问题。实际应用中也很少用到这个隔离级别，只有在非常需要确保数据的一致性而且可以接受没有并发的情况下，才考虑采用该级别。

![image-20210629084750568](D:\Desktop\知识整理\图片\image-20210629084750568.png)

**隔离级别实现原理：**数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

* ”可重复度“隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都在用整个试图；
* ”读提交“隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的；
* “读未提交”隔离级别下，直接返回记录上的最新值，没有试图概念；
* “串行化”隔离级别下，直接用加锁的方式来避免并行访问。

注：MVCC--数据库的多版本并发控制。

**MySQL的事务启动方式：**

* 显示启动事务语句，begin 或 start transaction。配套的提交语句使commit，回滚语句是rollback；
  * begin/start transaction 命令并不是一个事务的起点，在执行到他们之后的第一个操作InnoDB表的语句（第一个快照读语句），事务才真正启动。如果想要马上启动一个事务，可以使用start transaction with consistent snapshot 这个命令。
* set autocommit = 0，这个命令会将这个线程的自动提交关掉。意味着如果只执行一个select语句，这个事务就启动了，而且并不会自动提交，这个事务持续存在直到你主动执行commit 或 rollback语句，或者断开连接。

三种常见的数据结构：

* 哈希表：是一种以键-值（key-value）存储数据的结构。哈希表这种结构适用于只有等值查询的场景，比如Memcached以及其它一些NoSQL引擎。
* 有序数组：有序数组在等值查询和范围查询场景中的性能非常优秀。有序数组索引只适用于静态存储引擎。
* N叉树。

注：

* 页分裂：数据页满了之后，插入新值，根据B+树的算法，需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。页分裂影响数据页的利用率和系统性能。
* 聚簇索引、非聚簇索引、索引覆盖、最左前缀原则、索引下推（MySQL 5.6引入）

**InnoDB:**

* InnoDB采用MVCC来支持高并发，并且实现了四个标准的隔离级别。其默认级别是repeatable read（可重复读）。并且通过间隙锁（next-key locking）策略防止幻读的出现。间隙锁使得InnoDB不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。
* InnoDB表是基于聚簇索引建立的。InnoDB的索引结构和MySQL的其他存储引擎有很大的不同，聚簇索引对主键查询有很高的性能。不过它的二级索引（secondary index，非主键索引）中必须包含主键列。所以主键列很大的话，其他的所有索引都会很大。因此，所表上的索引较多的话，主键应当尽可能的小。InnoDB的存储格式是平台独立的，也就是说可以将数据和索引文件从Intel平台复制到PowerPC或者Sun SPARC平台。

**聚簇索引：**

聚集的数据有一些重要的优点：

* 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户ID来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘I/O。
* 数据访问更快，聚簇索引将索引和数据保存在同一个B-Tree中，因此从聚簇索引中获取数据通常比在非聚簇索引中查找要快。
* 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。

聚簇索引的一些缺点：

* 聚簇数据最大限度地提高了I/O密集型应用的性能，但如果数据全部都放在内存中，则访问的顺序就没那么重要了，聚簇索引也就没什么优势了。
* 插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到InnoDB表中速度最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表。
* 更新聚簇索引列的代价很高，因为会强制InnoDB将每个被更新的行移动到新的位置。
* 基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临“页分类（page split）”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳改行，这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间你。
* 聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。
* 二级索引（非聚簇索引）可能比想象得要更大，因为在二级索引得叶子节点包含了引用行得主键行。
* 二级索引访问需要两次索引查找，而不是一次。

**碎片：**

* 行碎片：值得四数据行被存储为多个地方的多个片段中。及时查询只从索引中访问一行记录，行碎片也会导致性能下降。
* 行间碎片：行间碎片是指逻辑上顺序的也，或者行在磁盘上不是顺序存储的。行间碎片对诸如全表扫描和聚簇索引扫描之类的操作有很大的影响，因为这些操作原本能够从磁盘上顺序存储的数据中获益。
* 剩余空间碎片：是指数据页中有大量的空余空间。这会导致服务器读取大量不需要的数据，从而造成浪费。

对于MyISAM表，这三类碎片化都可能发生，但InnoDB不会出现短小的行碎片，InnoDB会移动短小的行并重写到一个片段中。

在选择索引和编写利用这些索引的查询时，有如下三个原则始终需要记住：

* 1.单行访问是很慢的。特别是在机械硬盘存储中（SSD的随机I/O要快很多，不过这一点仍然成立）。如果服务器从存储中读取一个数据块只是为了获取其中一行，那么就浪费了很多工作。最好读取的块中能包含尽可能多所需要的行。使用索引可以创建位置引用以提升效率。
* 2.按顺序访问范围数据是很快的，这有两个原因。第一，顺序I/O不需要多次磁盘寻道，索引比随机I/O要快很多（特别是对机械硬盘）。第二，如果服务器能够按需要顺序读取数据，那么就不再需要额外的排序操作，并且GROUP BY查询也无须再做排序和将行按组进行计算了。
* 3.索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么存储引擎就不需要再回表查找行。这避免了大量的单行访问，而上面的第1点已经写明单行访问是很慢的。

------

MySQL锁：

* 全局锁：对整个数据库实例加锁。 Flush tables with read lock (FTWRL) --让整个库处于只读状态。使用场景：做全库逻辑备份。缺点：
  * 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
  * 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。
* 表级锁：
  * 表锁：表锁是最常用的处理并发的方式
  * 元数据锁（meta data lock，MDL）：MySQL 5.5版本中引入MDL，当对一个表做增删改查询操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。MDL不需要显式使用，是系统默认会加的。

* 行锁：针对数据表中行记录的锁。
* 间隙锁（Gap Lock）：为了解决幻读问题，锁的时两个值之间的空隙。间隙锁是在可重复读隔离级别下才会生效的。**间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的**。
* next-key lock：间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。
* 死锁：死锁解决策略：
  * 一种策略是直接进入等待，知道超时。整个超时时间可以通过参数innodb_lock_wait_timeout来设置，默认值是50s；
  * 另一种策略是发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启整个逻辑，默认为开启状态，一般情况下采用此策略。

**加锁规则：两个”原则“、两个”优化“ 和一个”bug“**

* 原则1：加锁的基本单位是next-key lock。next-key lock是前开后闭区间。
* 原则2：查找过程中访问到的对象才会加锁。
* 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
* 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
* 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。



**”快照“在MVCC里是怎么工作的**（事务见下图）：

![image-20210711171103231](D:\Desktop\知识整理\图片\image-20210711171103231.png)

* 在可重复读隔离级别下，事务在启动的时候就”拍了个快照“；
* InnDB里面每个事务都有一个唯一的事务ID，叫做transaction id，它是在事务开始ide时候向InnoDB的事务系统申请的，是按申请顺序严格递增的；
* 每行数据也都有多个版本的，每次十五更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息直接拿到他。

![image-20210711165252173](D:\Desktop\知识整理\图片\image-20210711165252173.png)

* 图中的三个虚线箭头，就是 undo log ，而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的；
* InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。

![image-20210711170330174](D:\Desktop\知识整理\图片\image-20210711170330174.png)

* 对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：

  * 1.如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；
  * 2.如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；
  * 3.果落在黄色部分，那就包括两种情况
    * a.  若 row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见；
    * b.  若 row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。

* 但当更新的时候，就不能在历史版本上更新了，否则该事务的更新就丢失了。事务B此时的set k=k+1是在（1,2）的基础上进行的操作。

  注：**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**除了update语句外，select语句如果加锁，也是当前读。

  所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode 或 for update，也都可以读到版本号是101的数据，返回的k的值是3。下面这两个select语句，就是分别加了读锁（S锁，共享锁）和写锁（X锁，排他锁）。

  ```
  mysql> select k from t where id=1 lock in share mode;
  mysql> select k from t where id=1 for update;
  ```

再往前一步，假设事务C不是马上提交的，而是变成了下面的事务C’，会怎么样呢？

![image-20210711171129189](D:\Desktop\知识整理\图片\image-20210711171129189.png)

事务C’没提交，也就是说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务C’释放这个锁，才能继续它的当前读。这时候事务A查询语句返回的是k=2。

，事务B查询结果k=3。。 --两阶段锁协议（两段锁协议是指每个事务的执行可以分为两个阶段：生长阶段（加锁阶段）和衰退阶段（解锁阶段））

**事务的可重复读的能力是怎么实现的？**：可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

**change buffer：**当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB会将这些更新操作还在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。chang buffer在内存中有拷贝，也会被写入到磁盘上（即change buffer是可以持久化的）。唯一索引的更新就不能使用change buffer（因为唯一索引需要将数数据读入内存，先判断唯一索引有没有冲突），实际上也只有普通索引可以使用。

优化分析：

* 1.对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
* 2.假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。此时应该关闭change buffer。设置方法：

```
innodb_change_buffer_max_size 来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。
```

**merge：**将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。

**buffer pool：**Buffer Pool就是数据库的一个内存组件，里面缓存了磁盘上的真实数据，然后我们的系统对数据库执行的增删改操作，其实主要就是对这个内存数据结构中的缓存数据执行的。

详细可参考：https://www.cnblogs.com/wxlevel/p/12995324.html

​		们在对数据库执行增删改操作的时候，不可能直接更新磁盘上的数据的，因为如果你对磁盘进行随机读写操作，那速度是相当的慢，随便一个大磁盘文件的随机读写操作，可能都要几百毫秒。如果要是那么搞的话，可能你的数据库每秒也就只能处理几百个请求了！ 在对数据库执行增删改操作的时候，实际上主要都是针对内存里的Buffer Pool中的数据进行的，也就是实际上主要是对数据库的内存里的数据结构进行了增删改。

![MySQL数据更新流程](D:\Desktop\知识整理\图片\3ddd109ee25242aba5c176c6af58ae2d~tplv-k3u1fbpfcp-zoom-1.image)

![img](D:\Desktop\知识整理\图片\565213-20200530221711156-63363016.png)

![img](D:\Desktop\知识整理\图片\565213-20200530221806004-1279067567.png)

​		其实每个人都担心一个事，就是你在数据库的内存里执行了一堆增删改的操作，内存数据是更新了，但是这个时候如果数据库突然崩溃了，那么内存里更新好的数据不是都没了吗？ MySQL就怕这个问题，所以引入了一个redo log机制，你在对内存里的数据进行增删改的时候，他同时会把增删改对应的日志写入redo log中，如下图。

![img](D:\Desktop\知识整理\图片\565213-20200530221829286-1677247683.png)

​		万一你的数据库突然崩溃了，没关系，只要从redo log日志文件里读取出来你之前做过哪些增删改操作，瞬间就可以重新把这些增删改操作在你的内存里执行一遍，这就可以恢复出来你之前做过哪些增删改操作了。 当然对于数据更新的过程，他是有一套严密的步骤的，还涉及到undo log、binlog、提交事务、buffer pool脏数据刷回磁盘，等等。

**MySQL选错索引的原因：**没能准确地判断出扫描行数。

注：使用前缀索引就用不上覆盖索引对查询性能的优化了，这是是否选择使用前缀索引时需要考虑的一个因素。

**引发数据库flush过程的场景：**

* 第一种场景：InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，rede log留出空间继续写。![image-20210711191156212](D:\Desktop\知识整理\图片\image-20210711191156212.png)

* 第二种场景：系统内存不足，当需要新的内存页，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。刷脏页一定会写盘，就保证了每个数据页有两种状态：
  * 一种是内存里存在，内存里就肯定是正确的结果，直接返回；
  * 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。
* 第三种场景：MySQL认为系统“空闲”的时候，有机会就刷一点“脏页”。
* 第四种场景：MySQL正常关闭的情况，这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会跟快。

#### **删除表数据分析：**

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table控制的：

* 这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
* 这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。

从MySQL 5.6.6版本开始，它的默认值就是ON了。建议不论是哪个版本，都将这个值设为ON。

数据删除流程：

![image-20210711193120047](D:\Desktop\知识整理\图片\image-20210711193120047.png)

* 删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。
* 如果删掉了一个数据页的所有数据，这个数据页就可以被复用了。
* 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。而当整个页从B+树里面摘掉以后，可以复用到任何位置。以图1为例，如果将数据页page A上的所有记录删除以后，page A会被标记为可复用。这时候如果要插入一条ID=50的记录需要使用新页的时候，page A是可以被复用的。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。
* 如果我们用delete命令把整个表的数据删除呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。
* 如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。
* 更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。

解决方案：新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中。可以使用alter table A engine=InnoDB命令来重建表。在MySQL 5.5版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自动完成转存数据、交换表名、删除旧表的操作。

**不同count（）用法分析：**

* **count(主键id)**，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。
* **count(1)**，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。
* **count(字段)**：
  * 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；
  * 如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。

* **count(\*)**：不取值，InnoDB直接返回行数。

结论：按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(*)，所以建议，尽量使用count(*)。



sort_buffer：MySQL给每个线程分配的用于排序的内存。

sort_buffer_size：MySQL为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。外部排序一般使用归并排序算法--MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。

rowid排序：单行的长度超过max_length_for_sort_data（MySQL中专门控制用于排序的行数据的长度的一个参数）定义的长度，排序的时候就只会取部分字段放入sort_buffer，完成排序后，再根据主键字段回表去除所有字段。

Using filesort：执行计划中Extra字段的值，表示需要执行排序操作。

Using index：执行计划中Extra字段的值，表示使用了覆盖索引。

Using temporary：执行计划中Extra字段的值，表示需要使用临时表。

------

QPS(Query Per Second) ：每秒查询率

TPS(Throughput) ：吞吐量

**MySQL是怎么保证数据不丢的：**

* binlog的写入机制：
  * 事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。
  * 一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。
  * 系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。
  * 每个线程有自己binlog cache，但是共用同一份binlog文件。
    * 图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。
    * 图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。

![image-20210712084556737](D:\Desktop\知识整理\图片\image-20210712084556737.png)

* redo log的写入机制：
  * 事务在执行过程中，生成的redo log是要先写到redo log buffer的。
  * redo log可能存在的三种状态：
    * 存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分；
    * 写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面，也就是图中的黄色部分；
    * 持久化到磁盘，对应的是hard disk，也就是图中的绿色部分。

![image-20210712085527215](D:\Desktop\知识整理\图片\image-20210712085527215.png)









































**常用命令：**

```
#展示自动提交事务是否开启，1或者ON表示启用 ，0或者OFF表示禁用
show VARIABLES LIKE 'autocommit';

#设置隔离级别
SET TRANSACTION ISOLATION LEVEL #隔离级别#;

#查询表的详细信息，其中Data_free为碎片空间（以字节为单位）,这部分包括了之前删除的行，以及后续可以被INSERT利用到的空间。
SHOW TABLE STATUS LIKE 'rs_agent_prod_order_bake_item';

#转换表的引擎
#该方法使用任何存储引擎。但需要执行很长时间。MySQL会按行将数据从原表复制到一张新的表中，再复制期间可能会消耗系统所有的I/O能力，同时原表上会加上读锁，所以，在繁忙的表上执行此操作要特别小心。
ALTER TABLE mytable ENGINE = INNODB;
#该方法即高效又安全
CREATE TABLE innodb_table LIKE myisam_table;
ALTER TABLE innodb_table ENGINE = INNODB;
INSERT INTO innodb_table SELECT * FROM myisam_table;

#测试某些特定操作的执行速度,该函数只是简单返回服务器执行表达式的时间，而不会涉及分析和优化的开销
SET @input := 'hello world';
SELECT BENCHMARK(10000000,MD5(@input)); --3.279s
SET @input := 'hello world';
SELECT BENCHMARK(10000000,SHA1(@input)); --4.564s

#LEFT(str,length) str是要提取子字符串的字符串;length是一个正整数，指定将从左边返回的字符数。
SELECT count(*) AS cnt, LEFT(SIM_NO,5) As pref FROM rs_sim_info_presell GROUP BY pref ORDER BY cnt DESC LIMIT 10

#重新组织表
OPTIMIZE TABLE rs_sim_info_presell;

#检查是否发生了表损坏
CHECK TABLE rs_sim_info_presell;

#尝试修复损坏的表
REPAIR TABLE rs_sim_info_presell;

#查看索引的基数（Cardinality）
show INDEX FROM rs_sim_info_presell

#通过次方式可以消除碎片化
ALTER TABLE rs_no_info_presell ENGINE = INNODB;

#连接状态，Sleep代表系统里面有一个空闲连接，默认8小时后断开连接，通过wait_timeout控制
show processlist

#查找持续时间超过60s的事务
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60

#用来重新统计索引信息
analyze table t

#算出这个列上有多少个不同的值
select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;

#用来测试磁盘随机读写的命令
 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
 
#脏页比例上限，默认值是75%
innodb_max_dirty_pages_pct

#脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的，具体的命令参考下面的代码：
select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;

#flush脏页时，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。
innodb_flush_neighbors

#配置限制了内存临时表的大小，默认值是16M
tmp_table_size

#查看设置，如慢查询是否开启等
show variables like "%slow%";

SHOW VARIABLES LIKE 'log_bin';
show binary LOGS;

show variables like 'expire_logs_days';
SET GLOBAL expire_logs_days=30;

show variables like 'innodb_flush_log_at_trx_commit';

show variables like 'slow_query%'
SET GLOBAL slow_query_log=ON;
SHOW VARIABLES LIKE 'long_query_time';
SET GLOBAL long_query_time=0.001;

show variables like 'general_log';

SHOW VARIABLES LIKE 'log_error';



```



------

### 图解mysql索引机制

也许很多人都背过 MySQL 调优的口诀，但是从来不理解为什么这样子写出的 sql 语句，可以有更高的性能。
而要理解其中的原由，就必须对 MySQL 底层的做一定的了解。

同时，为了进大厂，你也必须学会，才能去和面试官喷。。

下面我给出几道题目，你可以做一个自我检测：

什么叫 4K 对齐
如何存储空值数据
如何存储可变长数据
大 value 如何存储
什么是聚簇索引
InnoDB 没有定义主键会怎样
为什么推荐自增 id
什么是页目录
查询起始页是否会改变
什么是覆盖索引
为什么要符合最左前缀原则
熟悉 MySQL 的都知道 MySQL 有各种各样的存储引擎（InnoDB、MyISAM 等等）。
不过由于 InnoDB 支持事务，支持行锁，这样的特性十分适合我们生产环境中去使用，因而我们大部分情况下使用的都是 InnoDB 存储引擎。
我下面也是对 InnoDB 做详细地描述。

数据页
我们都知道，我们一般要用到 MySQL 数据库，一般都会将数据持久化到磁盘，而不是存储在内存中。
因为内存断电易失，此外，就是容量有限。

比如我们要在计算机磁盘上存储一段数据，那就会把它存在文件里，比如叫 “我很帅.txt”；
那我我们要查找数据的时候，要怎么去找，比如说找到里面的 “风流倜傥、玉树临风……”；
Linux 当中有 grep，awk 等等等等的命令，你也可以用 java 语言写一个程序，去查找。

不过这就涉及到一个概念，叫寻址，我们的磁盘寻址，一般是毫秒级别的；
然后，又涉及到带宽，一般几百兆，或者能达到一两个G。

然后做个简单的对比，对于内存，寻址则是纳秒级别的。
我们都知道 纳秒 <微秒 < 毫秒，1 毫秒 = 10^6 纳秒。
而且内存的带宽也要高于硬盘。

所以到目前为止，我们计算机的 I/O 都是瓶颈。
所以对于我们的硬盘来说，一次读取数据，绝对不会是一个字节一个字节去读的，因为磁盘的 I/O 是一个极慢的过程。

所以有这么一个概念，叫 4K 对齐，我们格式化磁盘的时候，也会看到有个东西叫 4K 对齐，那什么叫 4K 对齐？
就是我们读磁盘当中的数据的时候，假设我们就读一小点数据，几个字节；
但是真正从磁盘当中读出的数据，至少要有 4K，不管你用不用得到，都会存储到内存空间中（所以读出的数据永远是 4K 的倍数）。
假设你要读边上的数据了，那么就不用再去磁盘中去找，就可以节省时间。

这就是因为 I/O 这一瓶颈而不得不这么做。

而在我们的 MySQL 数据库中，对于我们的 InnoDB 存储引擎，存储的基本单位就是数据页；
存储的时候，默认的页要有 16KB 的大小。
所以我们在读取数据的时候，每次不是指读出你想要的那几条，一次至少读出的数据，就是一页，16KB。
而存储的时候，一次也最少要写入一页的数据。

那么我们接下来就要考虑数据页中是如何存放我们的数据的了。
（我不会把页里面所有的内容都列举出来，我们只需要分析有关的内容，便于理解）

首先，对于我们大量数据的存储，既然要分页，那么必须给每一个页标上一个唯一的号码，那么我们才能确认哪一页是哪一页；
我们可以将数据存储比作一本书，书有很多很多的页码，假设，一本书的页码全是一个数字，那你按页去分辨内容的时候一定会非常头疼。

#### 行格式

不要急，我们先来看最主要的内容，既然是数据库，那么最重要的，就是要存放我们的数据吧。
废话不多说，先建表：

![建表](D:\Desktop\知识整理\图片\2020041020234856.png)

为了方便使用数据库，我使用了 Navicat。
我们可以看到，新建的表，默认使用了 InnoDB 存储引擎（我的是 MySQL 5.7 版本）。
同时，字符集为 latin1

我们知道，我们的关系型数据库，数据是按行来存储的。
我们在创建表的时候，就会先定义表的行格式，也就是每一列分别存储什么类型的数据，数据占用空间是多少。
我们可以看一下，目前默认的行格式是什么：

![Dynamic](D:\Desktop\知识整理\图片\20200410204830733.png)

我先不说一行里面到底存储了多少内容，我们一点一点来分析，最后就能明白。

首先，我们看一下我们的表结构：

![表结构](D:\Desktop\知识整理\图片\2020041020502227.png)

我们的一行肯定要存储数据，所以至少要包含：每个字段所占用的大小。

id：int
首先 int 是一个固定长度的数字，占 32 位，也就是 4 个字节
并且是非空的，也就是无论哪一行，有多少行，这里肯定是要花费 4 个字节的空间来存储这个 int

a：int，不同的是，可以为空。

现在我们就要思考一下了，首先，假如有数据，那么占了 4 个字节没错；
可是要是没有数据呢，为空的情况怎么办？？？
我们可以想到，用一种特殊的字符来占据这个位置，来表示，这个位置是空的。
这么做有点就是，十分简单，而且行的大小不会动态改变；
但是，缺点显而易见，这里明明不存储数据，但是，就是要占用空间，假设空的字段很多，那岂不是要浪费很多很多的空间？？？
于是，我们还可以继续思考，为了节省空间，我们可以选择，不往这里存储数据，但是，这样就会产生问题：
这里没有数据了，那么空出来的位置，就要去存储下一列的数据，才能不浪费空间，那么数据的位置就不固定，就会出现错乱，我们怎么读到正确的数据呢？
所以，为了解决这个问题，我们来看 COMPACT 行格式（与 DYNAMIC 类似）：
在 COMPACT 行格式中，有一个字段叫 NULL标志位，用来记录，这一行中，哪些字段为空；

现在我们已经了解了 COMPACT 行格式中的一个额外的字段，
也就是说，我们的一行数据，真正的大小，是要大于一行中数据所占的大小的，
因为会有额外字段，去占用存储的空间。
（不过，要是我们设计表的时候，所有的字段都不为空，那么我们就可以节省这一个用来记录空字段的空间了）

我们继续看：

* c：varchar（20）：意味着 c 这个字段，只能存储最多 20 个字符。
  （在老版本中，这个长度表示的单位则是字节，不过现在已经表示字符了；
  因为如果要用字节来表示，很多字符占用的字节数不是固定的，因此很难把控这个字节数到底有多大）
* 我们先想，假如是定长字符串，那么存储空间就很容易把控，因为长度固定，根本不会变
* 那么，像这样，如果是可变长度的字符串呢？
  我们就得去额外的开辟字节，去存储字符的长度；
  这样，我们在读取的时候，才知道应该要读到哪里。
  所以，现在我们又知道了，在 COMPACT 行格式中，还有一个额外的字段，是用来存储可变字符长度的；
  这样，又再一次说明了，实际上一行记录的内容，要大于实际存储数据的内容。

所以，我们现在做一个测试：
我们建一个表，给出一个 varchar 65535 长度的字段；
不过惊喜地发现报错了：
上面说，最大的行大小为 65535，不过我现在给出的字段就是 65535，按道理应该正好对上最大值对吧。

![test](D:\Desktop\知识整理\图片\20200410211542436.png)

不过我们上面已经分析过，因为一个行之中，还要额外存储其他的字段，来保证一些特殊情况的处理，如可变长度字符串，空字段；
所以这会额外占用存储空间，就使得行大小会大于 65535，就会存不下了。
这时候，我把它改为 65532，就能成功了（65533 也不行的）。

![test](D:\Desktop\知识整理\图片\20200410213606933.png)

不过，你们还记不记得，一页的大小是多少？？
16K 对吧，也就是 16 * 1024 只有 16384 个字节的大小；
也就是还存不下我们的这一行数据。

那么，这样的数据该怎么办？
我们想一想，一页存不下，那就两页，三页……
把它分开，在各个页中分别存储每一小段数据。

想法很完美，那么，要实现这样一个目标，就要需要按顺序找出所有的页，
我们知道，数据结构有一种叫链表，
我们要实现这样一种存储方式，就可以在一个页中，存储一部分数据的值，然后再存储下一个页的地址，这样，便可以实现分页存储大段的数据了。

![在这里插入图片描述](D:\Desktop\知识整理\图片\20200411001359594.png)

还有一种方式，就是将数据和指针分离，一个页专门存放数据的地址，其他页专门存放数据：

![在这里插入图片描述](D:\Desktop\知识整理\图片\20200411001612762.png)

了解了行格式，我们继续往下探究。

#### **页目录**

我们现在往数据库里插入 8 条记录：

![插入记录](D:\Desktop\知识整理\图片\20200410203140491.png)

我们尝试一下把它们全部查找出来，
一看，确实都有了；
不过，有个小细节，就是查出来的数据，默认是按照 id 排好序的。
也就是说，我们的 InnoDB，已经帮我们做好了排序的工作。

![查找](D:\Desktop\知识整理\图片\20200410203213902.png)

之前我们建表的时候，明确指定了，id 就是这张表的主键，然后，存储的数据，会默认按照主键进行排序。
要是我们没有指定主键会怎么样？？？

如果没有的话，那么 InnoDB 会默认挑选一个唯一非空的字段来作为表的主键。
如果连一个唯一非空的字段都没有，那么就会自动生成一个 row_id，但是这个 row_id 对于我们用户来说是不可见的，也不可以被查找。

现在假设，我采用了 MyISAM 存储引擎，设置 id 主键，然后我们往其中插入数据

![MyISAM](D:\Desktop\知识整理\图片\2020041021584798.png)

我们查询一下：
可以发现，我们的查询结果并不是按照 id 主键排好序的。

![test](D:\Desktop\知识整理\图片\20200410220203836.png)

为什么偏偏 InnoDB 会产生这样的结果？？
那么，我们就要从它的存储结构谈起了。

首先，通过我们的观察，我们会发现，对于 InnoDB 存储引擎，我们插入的数据，会被自动排序。
我们知道，对于线性表来说，随机插入操作的时间复杂度为 O(n)，加入我们的 InnoDB 存储引擎采用顺序线性表来存储我们的数据，那么就很容易造成数据插入效率低下的为问题。
所以，实际上，行与行之间，采用链表的方式来进行相连。

![行排序](D:\Desktop\知识整理\图片\20200410221549600.png)

不过我们仔细一想，能这么简单吗？？
我们知道，链表虽然纯插入的操作复杂度低，但是，光要找出指定的数据，就需要从头至尾遍历，查找的时间复杂度为 O(n)，所以效率还是不够高的。
只要一个页个数据量开始变多，那么查询所花费的时间就可能会很长。

为了解决这个问题，在页中还有一部分存储空间，叫页目录（Page Director）。
我们存储在页中的数据，会被分组，其中，用一个页目录来专门存放每一组的起始 id。
（语言表述的话会难以理解，我放一张图）

![页目录](D:\Desktop\知识整理\图片\2020041022243964.png)

通过页目录，我们将大量的数据分为少量的组，然后先通过页目录，去查找属于哪一个组；
然后，从那一组的开头，去依次往后查询遍历。

比如，我们要找 id=2 的行记录，我们便可以先通过页目录，找到 1，然后是 3；
因为 2 比 1 大，然后又比 3 小，
这样，我们就可以确定，2 在第一组；
所以，我们从页里面的 1 的行，开始往后寻找，就可以找到 2。

这样，在数据量上升之后，查询的效率就会明显得到提高。

不过，在页目录中，并不需要用遍历的方式去查询，
首先，在页的目录中，我们只需要存储 id 主键，不用存储其它的字段数据；
而主键通常很小，所以页目录也很小；
所以我们完全可以，将其作为一个数组，然后采取二分查找的方式，去进行查找，
这样就可以进一步提升查询效率。

#### 聚集索引

到这里，我们已经探讨了，在一个页的情况下，我们要怎么存储数据。
由于一个页，大小只有 16KB，那么存储的数据总是有限的，所以，我们真正的生产数据，肯定会存到很多很多的页中去。
那么，当数据分页之后，又是什么样子的呢。

如果你还不知道，先别急着看答案，
按照道理，你想一想，数据应该用什么方式去存储。

首先，既然分页了，那么我们必须有一种结构，能把所有的页都找到。
仿照着之前行的存储方式，我们也可以将其存储成链表的样子。
在第一页上，记录下第二页的地址，我们就可以一页一页去查找。

但是，如果只是这样，那可不行。
就如同之前所描述的，一页中的多行记录一样，页中的行都要有页目录，更何况可以产生更多的页的数目呢。
所以，类似于页目录，我们还需要额外的一个页，去存储我们的页信息。

![页目录](D:\Desktop\知识整理\图片\20200410224246338.png)

就像这样，假如这时候我们需要去查找 id=8 的数据，
我们就会先通过目录页，找到记录所在的那一个页，就是 5 的所指向的那一页；
然后在那一个页中，我们通过页中的目录，去查找到数据行所在的那一组，就会找到 7；
最后，从 id=7 的那一行，往后遍历，就会找到 8 这一行记录。

假设数据量变大，那么查找的效率就会比从头开始查找高处许多：
先从起始页查找，很快就能定位到下一个页，然后再定位到下一个页；
这样最多 3、4 次，就能查找到指定的页；
然后在数据页中，只要按照页目录，迅速检索出行所在的组，然后就能找到。

假设从头往后遍历扫描，那么就会遍历成千上万个页，可见这样的存储结构确实十分高效。

然后看到这里，不知道你有没什么发现，这样一个存储结构像什么？
假设我把数据变多：

![树](D:\Desktop\知识整理\图片\20200410225126414.png)

这看起来不就是一棵树嘛。
实际上，我们的 InnoDB 底层采用的是 b+ 树。
这里推荐一个演示 b+ 树的网站：

[]: https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html

可以自己快速的体验和理解 b+ 树，
就像这样子：

![b+树演示](D:\Desktop\知识整理\图片\20200410225805135.png)

而我们之前描述的，迅速查找的页，就叫做索引。
我们上面也已经探讨过了，在 InnoDB 中，必须是有主键的，而有了主键，就一定会有主键索引，
我们刚才演示确实是记录按照 id 排好顺序的。

而主键索引又叫聚簇索引、聚集索引。
意思就是，所有的数据都存储在叶子节点中，
就像这样：

![聚簇索引](D:\Desktop\知识整理\图片\20200410231539991.png)

不过虽然采用了 b+ 树的形式确实是大大提高了查询速率。
不过这里又有一个小细节，就是当一个页存不下之后，新增一个页，创建出一个页表，那么查询的起始页就会改变位置。

![起始页](D:\Desktop\知识整理\图片\20200410232154706.png)

如果我们的表，它的起始页一直在变化，那么肯定是不好的。
InnoDB 它是怎么做的呢？
首先，它会将起始页复制出一个；
然后，将原先的起始页，修改成为新的页目录。

![起始页](D:\Desktop\知识整理\图片\20200410232635867.png)

理清了存储的数据结构，我们现在再来一个问题，
就是为什么我们存储的主键字段，要尽可能的小，并且是递增的？
也就是为什么推荐我们用自增 int 主键？

通过上面的学习，想来你们应该能够明白。
因为我们的页目录，包括目录页，里面都不存储行里面所有的记录，只包含一个 id 索引，和目标地址的指针。
那么，现在，假设我们用 8 字节的 id，加上 6 字节的指针。
那么，一个页，16KB，就可以存放大约 1170 条记录，这样我们的索引目录的数量就会比较少，我们的树的层数、高度就会比较低，就可以减少磁盘 I/O 带来的开销。

这样，假设树的高度为 3，我们的 3 层树，就可以承载 1170 * 1170 * 16KB 的数据量（大约 21G）；
要是树再高一层，那就再乘上 1170，这样，数据量就可以有二十多 TB。
而我们的 I/O 开销，就只有树的高度，这几次。
也就是，假设树有 3 层，我们找到数据行，只需要找 3 页，就能找到，所以，索引是十分高效的。

而且，如果是递增的，那么当数据页不够时，增加新的数据页即可。
否则，如果插在中间，那就得把当前数据页的排在后面的数据，挤到下一页去，产生页分裂，这时非常低效的。

#### 非主键索引

之前我都是再说主键索引，不过 InnoDB 也可以建立非主键索引。
它们唯一的区别就是，聚集索引存储了每一行的所有数据，但是其它的索引，就不会存储行数据，而只是在存储了主键的值。
这样的话，当我们通过某个字段，查找到了主键 id，但是我们不能直接获得其它列的数据，我们还必须通过这个 id，回到主键索引，去查取整个行的记录。

![非主键索引](D:\Desktop\知识整理\图片\20200410234437169.png)

不过我们知道，对于表字段建立索引，可以指定多个字段，共同建立起一个索引，叫联合索引。
我们现在明白，索引是一种 b+ 树的结构，也就是会对字段的值进行排好序，方便我们的查找。

看到这里，你也就应该要能思考出，为什么覆盖索引会有查询优势，
因为，查询的字段，就已经是非主键索引的排序字段了，我们在这棵索引树上可以直接获取到字段的值，
而不用去回表扫描，增大 I/O 的开销。

不过对于联合索引，多个字段的情况，那么它是如何排序的？

现在我先对字段 a、b、c 建立了一个联合索引：

![联合索引](D:\Desktop\知识整理\图片\20200410235251437.png)

然后我们查询一下索引中的字段，
我们可以发现，确实是排序过的：

首先按照 a 排序，
其次如果 a 相等，就按照 b 排序
再然后，如果 a、b 都相等了，就按照 c 排序。

![联合索引排序](D:\Desktop\知识整理\图片\20200410235945919.png)

然后就可以很容易解释，为什么对于联合索引的查询，不按索引顺序来写条件，就会导致索引失效了。
因为假设，没有 a 字段的明确指定，那么 b 的排序就不是完全按照次序的，a 每发生变化，b 的排序就会错乱；
只有 a 确定了，那么查询到的 b 就是排好序的，那么就可以进行检索。
就比如：

```mysql
select * from test where a=1 and b=1 and c=1;
```

这样查找的时候，因为 a 的索引是有序的，就会先找到 a；
找到 a 之后，b 就是有序的，就可以通过索引迅速找到 b；
找到 b 之后，那么 c 就是有序的，就可以通过索引快速找到 c。
那么假设 sql 是这样：

```mysql
select * from test where a=1 and c=1;
```

这样查找的时候，因为 a 的索引是有序的，就会先找到 a；
但是由于 b 没有确定，所以 c 无法保证有序，就无法通过索引再进行快速分治查找。
因而 c 索引失效
那么再假设 sql 是这样：

```mysql
select * from test where and a=1 and b>1 and c=1;
```

这样查找的时候，因为 a 的索引是有序的，就会先找到 a；
找到 a 之后，b 就是有序的，就可以迅速查找到 b=1 的位置，然后，依次往后遍历出所有的 b 都是大于 1 的；
但是，由于 b 有很多很多个符合要求，所以 b 也不是固定的，那么就导致 c 无法保证有序，因而 c 就无法通过索引分治快速查找
所以，c 索引再次失效。

#### 总结

学到这里，那你应该能大致理解，对于 InnoDB，是如何存储数据的，索引又是一种什么东西；
那么，在对于数据库 sql 语句的编写，你也能大致明白，底层的逻辑是什么样子的，也就能因此避免掉一些性能低效的 sql 语句；
这样，你也就不用去刻意背诵 sql 优化口诀，而是能真正明白，怎样的 sql 是高效的。

不过，我这里也只是分析了底层的存储结构，关于 InnoDB 还有很多知识需要学习，所以要做到真正精通，还需要大家不断努力。

























