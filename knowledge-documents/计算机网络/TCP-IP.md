### TCP/网络模型

![image-20210611132727697](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210611132727697.png)

应用层：为用户提供应用功能，HTTP
传输层：为应用层提供网络支持  TCP、UDP
网络层：实际的传输功能  IP
数据链路层：为网络层提供链路级别传输的服务 ARP
物理层：为数据链路层提供二进制传输的服务（把数据包转换成电信号或光信号，从而可以在物理介质中传输）

#### **通信与7个分层**

![image-20210611133006853](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210611133006853.png)

### HTTP篇

![HTTP](D:\Desktop\知识整理\图片\HTTP.png)

**HTTP概念:**HTTP（HyperText Transfer Protocol，**超文本** **传输** **协议** ）的协议作为规范，完成从客户端到服务器端等一系列运作流程。
<!--超文本：超越了普通文本的文本，它是文字、图片、视频的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。-->

**五大类HTTP状态码**

![image-20210615183623496](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210615183623496.png)



**HTTP常见字段**

Host：客户端发送请求时，用来指定服务器的域名
Content-Length：服务器返回数据，表明本次回应的数据长度，如 Content-Length: 1000
Connection：常用于客户端要求服务端要求服务器使用TCP持久连接，以便其他请求复用，持久连接需指定字段值为Keep-Alive。如 Connection: keep-alive
Content-Type：用于服务器回应时，告诉客户端，本次数据是什么格式。如 Content-Type: text/html; charset=utf-8
Accept：客户端声明自己可以接收哪些数据格式。如 Accept:* /*
Content-Encoding：服务器返回的数据使用了什么压缩格式。如 Content-Encoding: gzip

GET与POST

Get：请求**从服务器获取资源**，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。安全且幂等
POST：向 URI 指定的资源提交数据，数据就放在报文的body里。不安全且不幂等

<!--在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。-->
<!--所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。（只读一般都是幂等的，而修改服务器上的资源，都为不幂等的）-->

**HTTP特性**

HTTP1.1 优点：简单、灵活和易于扩展、应用广泛和跨平台。

HTTP1.1 缺点：无状态、明文传输和不安全

* 通信使用明问（不加密），内容可能回被窃听。⽐如，账号信息容易泄漏，那你号没了。 --**窃听风险**

* 不验证通信⽅的身份，此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。-**-篡改伪装**

* ⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。--**冒充风险**

HTTP1.1 性能：

* 长连接：也叫持久连接，从而减少了TCP 连接的᯿复建⽴和断开所造成的额外开销，减轻了服务器端的负载。

* 管道网络传输：即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以**减少整体的响应时间。**可能出现的问题：服务器还是按照**顺序**，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「**队头堵塞**」。
* 队头阻塞：当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「**队头阻塞**」。**好⽐上班的路上塞⻋**。

HTTP 与 HTTPS 有区别

* 1. HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。

* 2. HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。

* 3. HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。

* 4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

HTTPS 解决了 HTTP 的哪些问题

* **信息加密**：交互信息⽆法被窃取，但你的号会因为「⾃身忘记」账号⽽没。

* **校验机制**：⽆法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾⼴告。

* **身份证书**：证明淘宝是真的淘宝⽹，但你的钱还是会因为「剁⼿」⽽没。

HTTPS 是如何解决上⾯的三个⻛险的？

* **混合加密**的⽅式实现信息的**机密性**，解决了窃听的⻛险。--对称加密和非对称加密结合

* **摘要算法**的⽅式来实现**完整性**，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。

* 将服务器公钥放⼊到**数字证书**中，解决了冒充的⻛险。--CA（数字证书认证机构）

**HTTPS 是如何建⽴连接的？其间交互了什么？**

SSL/TLS 协议基本流程：

* 客户端向服务器索要并验证服务器的公钥。

* 双⽅协商⽣产「会话秘钥」。

* 双⽅采⽤「会话秘钥」进⾏加密通信。

**SSL/TLS 的「握⼿阶段」涉及四次通信（SSL/TLS 1.3 优化了过程，只需要 1 个 RTT 往返时延，也就是只需要 3 次握⼿）：**

* *1. ClientHello*

  ⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。

  在这⼀步，客户端主要向服务器发送以下信息：

  （1）客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

  （2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。

  （3）客户端⽀持的密码套件列表，如 RSA 加密算法。

* *2. SeverHello*

  服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：

  （1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。

  （2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。

  （3）确认的密码套件列表，如 RSA 加密算法。

  （4）服务器的数字证书。

* *3.*客户端回应 Certificate*

  客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息：

  （1）⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。

  （2）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

  （3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验。

上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协商的加密算法，**各⾃⽣成**本次通信的「会话秘钥」。

* *4.* 服务器的最后回应

  服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发⽣最后的信息：

  （1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

  （2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。

⾄此，整个 SSL/TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP协议，只不过⽤「会话秘钥」加密内容。

#### HTTP/1.1、HTTP/2、HTTP/3 演变

**HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？**

* 使用TCP长连接的方式改善了HTTP/1.0短连接造成的性能开销
* 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

 **HTTP/1.1 还是有性能瓶颈：**

* 请求/响应头部（Header）未经压缩就发送，首部信息延迟越多延迟越大。只能压缩Body的部分；
* 发送冗长的首部。每次互相发送相同的首部造成的浪费较多’
* 服务器是按请求的顺序相应的，如果服务器响应慢，会导致客户端一直请求不到数据，也就是队头阻塞；
* 没有请求优先级控制；
* 请求只能从客户端开始，服务器只能被动相应。

**针对HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？**

HTTP/2协议是基于HTTPS的，所以HTTP/2的安全性也是有保障的。

* 头部压缩 --HPACK算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就**提⾼速度**了。
* 二进制格式 --头信息帧和数据帧
* 数据流 --每个请求或回应的所有数据包称为一个数据流（Stream）：每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。
* 多路复用 --HTTP/2 是可以在**⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应**，从而消除了队头阻塞问题。
* 服务器推送 --HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，**减少延时的等待**，也就是服务器推送（Server Push，也叫 Cache Push）。

**HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？**

HTTP/2主要的问题在于，多个HTTP请求在服用一个TCP连接，下层的TCP协议是不知道有多少个HTTP请求的。所以一旦发生了丢包现象，就会出发TCP的重传机制，这样在一个TCP连接中的**所有的HTTP请求都必须等待这个丢了的包被重传回来。**

这都是基于 TCP 传输层的问题，所以 **HTTP/3** **把** **HTTP** **下层的** **TCP** **协议改成了** **UDP**！

![image-20210616082236843](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616082236843.png)

 UDP 是不可靠传输的，但基于 UDP 的 **QUIC** **协议** （QUIC 是⼀个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复⽤的协议。）可以实现类似 TCP 的可靠性传输。UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部᯿传问题。

**HTTP/1.1如何优化？**

* 尽量避免发送*HTTP*请求 
  * **缓存：**客户端会把第⼀次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，⽽响应作为 value，两者形成映射关系。这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。毋庸置疑，读取本次磁盘的速度肯定⽐⽹络请求快得多。
* 在需要发送*HTTP*请求时，考虑如何减少请求次数
  * 减少重定向请求次数 --重定向的工作交由代理服务器完成，就能减少HTTP请求次数了
  * 和并请求 --合并请求的⽅式就是合并资源，以⼀个⼤资源的请求替换多个⼩资源的请求。
  * 延迟发送请求 --按需访问资源
* 减少服务器的*HTTP*相应的数据大小
  * 无损压缩 --⽆损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合⽤在⽂本⽂件、程序可执⾏⽂件、程序源代码。 --gzip、Brotli 就是⽐较常⻅的⽆损压缩。
  * 有损压缩 --**WebP格式**

SSL/TLS

RSA密钥协商算法的最大问题是不支持前向保密，为解决这一问题，就有了DH密钥协商算法

![image-20210616090104808](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616090104808.png)

DH 密钥交换过程中，**即使第三⽅截获了** **TLS** **握⼿阶段传递的公钥，在不知道的私钥的情况下，也是⽆法计算出**

**密钥的，⽽且每⼀次对称加密密钥都是实时⽣成的，实现前向保密**。

-->因为 DH 算法的计算效率问题，后⾯出现了 ECDHE 密钥协商算法，我们现在⼤多数⽹站使⽤的正是 ECDHE 密

钥协商算法。

**使⽤了** **ECDHE****，在** **TLS** **第四次握⼿前，客户端就已经发送了加密的** **HTTP** **数据**，所以，**ECDHE** **相⽐** **RSA** **握⼿过程省去了⼀个消息往返的时间**。

**RSA 和 ECDHE 握⼿过程的区别：**

* RSA密钥协商算法不支持向前保密，ECDHE密钥协商算法支持向前保密
* 使用RSA密钥协商算法，TLS完成四次握手后，才能进行应用数据传输，而对于ECDHE算法，客户端可以不用等服务端的最后一次TLS握手，就可以提前发出加密的HTTP数据，节省了一个消息的往返时间；
* 使用ECDHE，在TLS第2次握手中，会出现服务器端发出的Server Key Exchange 消息，而RSA握手过程没有该消息。

**HTTPS** **如何优化？**

分析性能损耗：

* 第⼀个环节， TLS 协议握⼿过程（最⻓可以花费掉 2 RTT）；
  * 对于 ECDHE 密钥协商算法，握⼿过程中会客户端和服务端都需要临时⽣成椭圆曲线公私钥；
  * 客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，⽬的是验证服务器的证书是否有被吊销；
  * 双⽅计算 Pre-Master，也就是对称加密密钥；
* 第⼆个环节，握⼿后的对称加密报⽂传输。 --主流的对称加密算法 AES、ChaCha20 性能都是不错的，此环节的性能消耗非常小。

优化方向

* 硬件优化  --**HTTPS** **协议是计算密集型，⽽不是** **I/O** **密集型**，所以不能把钱花在⽹卡、硬盘等地⽅，应该花在 CPU 上。

* 软件优化 --软件升级和协议优化（对 密钥交换过程 进行优化，优先选用 ECDHE；证书优化；会话复用）
  证书验证优化：

  * CRL： 称为证书吊销列表（*Certificate Revocation List*），这个列表是由 CA 定期更新，列表内容都是被撤销信任的证书序号，如果服务器的证书在此列表，就认为证书已经失效，不在的话，则认为证书是有效的。
  * OCSP：现在基本都是使⽤ OCSP ，名为在线证书状态协议（*Online Certificate Status Protocol*）来查询证书的有效性，它的⼯作⽅式是**向** **CA** **发送查询请求，让** **CA** **返回证书的有效状态**。
  * OCSP Stapling：于是为了解决这⼀个⽹络开销，就出现了 OCSP Stapling，其原理是：服务器向 CA 周期性地查询证书状态，获得⼀个带有时间戳和签名的响应结果并缓存它。

  会话复用分两种

  * 第⼀种叫 Session ID：**客户端和服务器⾸次** **TLS** **握⼿连接后，双⽅会在内存缓存会话密钥，并⽤唯⼀的Session ID **来标识，Session ID 和会话密钥相当于 key-value 的关系。
    当客户端再次连接时，hello 消息⾥会带上 Session ID，服务器收到后就会从内存找，如果找到就直接⽤该会话密钥恢复会话状态，跳过其余的过程，只⽤⼀个消息往返就可以建⽴安全通信。当然为了安全性，内存中的会话密钥会定期失效。 --可能导致 重放攻击；不具备前向安全
    缺点：
    * 服务器必须保持每⼀个客户端的会话密钥，随着客户端的增多，**服务器的内存压⼒也会越⼤**。
    * 现在⽹站服务⼀般是由多台服务器通过负载均衡提供服务的，**客户端再次连接不⼀定会命中上次访问过的服****务器**，于是还要⾛完整的 TLS 握⼿过程；
  * 第⼆种叫 Session Ticket：为了解决 Session ID 的问题，就出现了 Session Ticket，**服务器不再缓存每个客户端的会话密钥，⽽是把缓存的⼯作交给了客户端**，类似于 HTTP 的 Cookie。
  * **Pre-shared Key**：前⾯的 Session ID 和 Session Ticket ⽅式都需要在 1 RTT 才能恢复会话。⽽ TLS1.3更为⽜逼，对于᯿连 TLS1.3 只需要 **0 RTT**，原理和 Ticket 类似，只不过在᯿连时，客户端会把 Ticket和HTTP 请求⼀同发送给服务端，这种⽅式叫 **Pre-shared Key**。 --可能导致 重放攻击；不具备前向安全

<!--应对重放攻击可以给会话密钥设定⼀个合理的过期时间，以及只针对安全的 HTTP 请求如 GET/HEAD 使⽤会话重用。-->

**HTTP/2⽜逼在哪？**

* 兼容HTTP/1.1

* 头部压缩

* 服务器主动推送资源

* 二进制帧
  ![image-20210616153914225](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616153914225.png)

* 并发传输

  * HTTP/1.1 的实现是基于请求-响应模型的。同⼀个连接中，HTTP 完成⼀个事务（请求与响应），才能处理下⼀个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是⽆法发送的，也造成了**队头阻塞**的问题。

  * ⽽ HTTP/2 就很⽜逼了，通过 Stream 这个设计，**多个** **Stream** **复⽤⼀条** **TCP** **连接，达到并发的效果**，解决了HTTP/1.1 队头阻塞的问题，提⾼了 HTTP 传输的吞吐量。

  ​	为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。

![image-20210616154531830](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616154531830.png)

* 1 个 TCP 连接包含⼀个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；
* Stream ⾥可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；
* Message ⾥包含⼀条或者多个 Frame，Frame 是 HTTP/2 最⼩单位，以⼆进制压缩格式存放 HTTP/1 中的内容（头部和包体）；

因此，我们可以得出 2 个结论：HTTP 消息可以由多个 Frame 构成，以及 1 个 Frame 可以由多个 TCP 报⽂构成。

#### **HTTP/3特性**

**美中不⾜的 HTTP/2**

HTTP/2 通过头部压缩、⼆进制编码、多路复⽤、服务器推送等新特性⼤幅度提升了 HTTP/1.1 的性能，⽽美中不⾜的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。

* 队头阻塞：HTTP/2 多个请求是跑在⼀个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待᯿传，那么就会阻塞该TCP 连接中的所有请求。
* TCP与TLS的握手时延迟：发起 HTTP 请求时，需要经过 TCP 三次握⼿和 TLS 四次握⼿（TLS 1.2）的过程，因此共需要 3 个 RTT 的时延才能发出请求数据。
* 网络迁移需要重新连接：⼀个 TCP 连接是由四元组（源 IP 地址，源端⼝，⽬标 IP 地址，⽬标端⼝）确定的，这意味着如果 IP 地址或者端⼝变动了，就会导致需要 TCP 与 TLS ᯿新握⼿，这不利于移动设备切换⽹络的场景，⽐如 4G ⽹络环境切换成WIFI。

HTTP/3做了哪些改变

* 把**传输层协议替换成 UDP**

![image-20210616165148068](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616165148068.png)

QUIC 协议的特点

* 无队头阻塞：QUIC 连接上的多个 Stream 之间并没有依赖，都是独⽴的，某个流发⽣丢包了，只会影响该流，其他流不受影响。
* 更快的连接建立：
  * 对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在⼀起，需要分批次来握⼿，先 TCP 握⼿，再 TLS 握⼿。
  * HTTP/3 在传输数据前虽然需要 QUIC 协议握⼿，这个握⼿过程只需要 1 RTT，握⼿的⽬的是为确认双⽅的「连接ID」，连接迁移就是基于连接 ID 实现的。
  *  HTTP/3 的 QUIC 协议并不是与 TLS 分层，⽽是QUIC 内部包含了 TLS，它在⾃⼰的帧会携带 TLS⾥的记录，再加上 QUIC使⽤的是TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在第⼆次连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息+ TLS 信息）⼀起发送，达到 0-RTT的效果。
* 连接迁移：
  * 在前⾯我们提到，基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端⼝、⽬的 IP、⽬的端⼝）确定⼀条 TCP 连接，那么当移动设备的⽹络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后᯿新建⽴连接，⽽建⽴连接的过程包含 TCP 三次握⼿和 TLS 四次握⼿的时延，以及 TCP 慢启动的减速过程，给⽤户的感觉就是⽹络突然卡顿了⼀下，因此连接的迁移成本是很⾼的。
  * ⽽ QUIC 协议没有⽤四元组的⽅式来“绑定”连接，⽽是通过**连接** **ID**来标记通信的两个端点，客户端和服务器可以各⾃选择⼀组 ID 来标记⾃⼰，因此即使移动设备的⽹络变化后，导致 IP 地址变化了，只要仍保有上下⽂信息（⽐如连接 ID、TLS 密钥等），就可以“⽆缝”地复⽤原连接，消除᯿连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双⽅的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。



### TCP篇

定义：TCP 是**⾯向连接的、可靠的、基于字节流**的传输层通信协议。

* **⾯向连接**：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是⽆法做到的；

  **连接定义**：用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括**Socket**、**序列号**和**窗口大小**称为连接。

* **可靠的**：⽆论的⽹络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报⽂⼀定能够到达接收端；

* **字节流**：消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重复」的报⽂会⾃动丢弃。

TCP基本认识：TCP 是⼀个⼯作在**传输层**的**可靠**数据传输的服务，它能确保接收端接收的⽹络包是**⽆损坏、⽆间隔、⾮冗余和按序的。**![image-20210616171628822](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616171628822.png)



**序列号**：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就 			 「累加」⼀次该「数据字节数」的⼤⼩。**⽤来解决⽹络包乱序问题。**

**确认应答号**：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数					  据都已经被正常接收。**⽤来解决不丢包的问题。**

**控制位：**

* ***ACK***(Acknowledgement 致谢)：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。

* ***RST***(RESET 重启)：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。

* ***SYN***(Synchronize Sequence Numbers 同步序列号)：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。

* ***FIN***(finish 完成)：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。

建⽴⼀个 TCP 连接是需要客户端与服务器端达成三个信息的共识。

* 有IP地址和端口号组成
* 用来解决乱序问题等
* 用来做流量控制

如何唯⼀确定⼀个 TCP 连接呢？

* 源地址 --32位，在IP头部中，作用时通过IP协议发送报文给对方主机
* 源端口 --16位，在TCP头部中，作用是告诉TCP协议应该把报文发给哪个进程
* 目标地址 --32位，在IP头部中，作用时通过IP协议发送报文给对方主机
* 目标端口 --16位，在TCP头部中，作用是告诉TCP协议应该把报文发给哪个进程

![image-20210616182932930](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616182932930.png)



![image-20210616185525792](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210616185525792.png)

* ⽬标和源端⼝：主要是告诉 UDP 协议应该把报⽂发给哪个进程。
* 包⻓度：该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。
* 校验和：校验和是为了提供可靠的 UDP ⾸部和数据⽽设计。



**TCP** **和** **UDP** **区别：**

* 连接
  * TCP时面向连接的传输层协议，传输数据前先要建立连接
  * UDP是不需要连接，即刻传输数据
* 服务对象
  * TCP是一对一的两点服务，即一条连接只有两个端点
  * UDP支持一对一、一对多、多对多的交互通信
* 可靠性
  * TCP是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达
  * UDP是尽最大努力交付，不保证可靠交付数据
* 拥塞控制、流量控制
  * TCP有拥塞控制和流量控制机制，保证数据传输的安全性
  * UDP则没有，即使网络非常拥堵了，也不会影响UDP的发送速率

* 首部开销
  * TCP 首部长度较长，会有一定的开销，首部在没有使用 选型 字段时是20个字节，如果使用了 选项 字段则会变长的
  * UDP首部只有8个字节，并且是固定不变的，开销较小
* 传输方式
  * TCP 是流式传输，没有边界，但保证顺序和可靠
  * UDP是一个包一个包的发送，是有边界的，但可能会丢包和乱序
* 分片不同
  * TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。
  * UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则就需要᯿传所有的数据包，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。

**TCP** **和** **UDP** **应⽤场景：**

* 由于 TCP 是⾯向连接，能保证数据的可靠性交付，因此经常⽤于：
  * FTP ⽂件传输
  * HTTP / HTTPS

* 由于 UDP ⾯向⽆连接，它可以随时发送数据，再加上UDP本身的处理既简单⼜⾼效，因此经常⽤于：
  * 包总ᰁ较少的通信，如 DNS 、 SNMP 等
  * 视频、⾳频等多媒体通信
  * ⼴播通信

**TCP 三次握⼿过程和状态变迁**

![image-20210617081146699](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617081146699.png)

* ⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态
* 三次握手的第一个报文：客户端会随机初始化序号（ client_isn ），将此序号置于 TCP ⾸部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报⽂。接着把第⼀个 SYN 报⽂发送给服务端，表示向服务端发起连接，该报⽂不包含应⽤层数据，之后客户端处于 SYN-SENT 状态。
* 三次握手的第二个报文：服务端收到客户端的 SYN 报⽂后，⾸先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填⼊TCP ⾸部的「序号」字段中，其次把 TCP ⾸部的「确认应答号」字段填⼊ client_isn + 1 , 接着把 SYN和 ACK 标志位置为 1 。最后把该报⽂发给客户端，该报⽂也不包含应⽤层数据，之后服务端处于 SYNRCVD 状态。
* 三次握手的第三个报文：客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂，⾸先该应答报⽂ TCP ⾸部 ACK 标志位置为 1 ，其次「确认应答号」字段填⼊ server_isn + 1 ，最后把报⽂发送给服务端，这次报⽂可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。
* 服务器收到客户端的应答报⽂后，也进⼊ ESTABLISHED 状态。

从上⾯的过程可以发现**第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的**，这也是⾯试常问的题。

**如何在 Linux 系统中查看 TCP 状态？**

在 Linux 可以通过 netstat -napt 命令查看。

![image-20210617081500272](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617081500272.png)

**为什么是三次握⼿？不是两次、四次？**

在前⾯我们知道了什么是 **TCP** **连接**：⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括**Socket**、**序列号和窗⼝⼤⼩**称为连接。

所以，重要的是**为什么三次握⼿才可以初始化Socket、序列号和窗⼝⼤⼩并建⽴** **TCP** **连接。**

接下来以三个⽅⾯分析三次握⼿的原因：

* 三次握手可以防止历史连接的建立（主要原因）
* 三次握手可以同步双方的初始序列号
  * TCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素，它的作⽤： 
    * 接收可以去除重复的数据
    * 接收方可以根据数据包的序列号按序接收
    * 可以表示发送出去的数据包中，哪些是已被对方收到的
* 三次握手能减少双放不必要的资源开销

**因此，不使⽤「两次握⼿」和「四次握⼿」的原因：**

* 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
* 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

**为什么客户端和服务端的初始序列号 ISN 是不相同的？**

* 如果⼀个已经失效的连接被᯿⽤了，但是该旧连接的历史报⽂还残留在⽹络中，如果序列号相同，那么就⽆法分辨出该报⽂是不是历史报⽂，如果历史报⽂被新的连接接收了，则会产⽣数据错乱。
* 所以，每次建⽴连接前᯿新初始化⼀个序列号主要是为了通信双⽅能够根据序号将不属于本连接的报⽂段丢弃。
* 另⼀⽅⾯是为了安全性，防⽌⿊客伪造的相同序列号的 TCP 报⽂被对⽅接收。

**什么是 SYN 攻击？如何避免 SYN 攻击？**

* *SYN* 攻击：我们都知道 TCP 连接建⽴是需要三次握⼿，假设攻击者短时间伪造不同 IP 地址的 SYN 报⽂，服务端每接收到⼀个 SYN 报⽂，就进⼊ SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报⽂，⽆法得到未知 IP 主机的ACK 应答，久⽽久之就会**占满服务端的** **SYN** **接收队列（未连接队列）**，使得服务器不能为正常⽤户服务。
* 避免 *SYN* 攻击⽅式⼀：其中⼀种解决⽅式是通过修改 Linux 内核参数，控制队列⼤⼩和当队列满时应做什么处理。
  * 当⽹卡接收数据包的速度⼤于内核处理的速度时，会有⼀个队列保存这些数据包。控制该队列的最⼤值如下参数：net.core.netdev_max_backlog
  * SYN_RCVD 状态连接的最⼤个数：net.ipv4.tcp_max_syn_backlog
  * 超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：net.ipv4.tcp_abort_on_overflow

* 避免 *SYN* 攻击⽅式⼆：

我们先来看下 Linux 内核的 SYN （未完成连接建⽴）队列与 Accpet （已完成连接建⽴）队列是如何⼯作的？

![image-20210617084313824](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617084313824.png)

正常流程：

* 当服务端接收到客户端的 SYN 报⽂时，会将其加⼊到内核的「 SYN 队列」；

* 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报⽂；

* 服务端接收到 ACK 报⽂后，从「 SYN 队列」移除放⼊到「 Accept 队列」；

* 应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出连接。

![image-20210617084408533](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617084408533.png)

应⽤程序过慢：如果应⽤程序过慢时，就会导致「 Accept 队列」被占满。

![image-20210617084501347](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617084501347.png)

受到 SYN 攻击：如果不断受到 SYN 攻击，就会导致「 SYN 队列」被占满。

tcp_syncookies 的⽅式可以应对 SYN 攻击的⽅法：net.ipv4.tcp_syncookies = 1

![image-20210617084548962](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617084548962.png)

* 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进⼊「 SYN 队列」；

* 计算出⼀个 cookie 值，再以 SYN + ACK 中的「序列号」返回客户端，

* 服务端接收到客户端的应答报⽂时，服务器会检查这个 ACK 包的合法性。如果合法，直接放⼊到「 Accept队列」。

* 最后应⽤通过调⽤ accpet() socket 接⼝，从「 Accept 队列」取出的连接。

##### TCP 四次挥⼿过程和状态变迁

![image-20210617084739364](C:\Users\Daijf\AppData\Roaming\Typora\typora-user-images\image-20210617084739364.png)

* 客户端打算关闭连接，此时会发送一个TCP首部FIN标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入  FIN_WAIT_1 状态。
* 服务端收到该报⽂后，就向客户端发送 ACK 应答报⽂，接着服务端进⼊ CLOSED_WAIT 状态。
* 客户端收到服务端的 ACK 应答报⽂后，之后进⼊ FIN_WAIT_2 状态。
* 等待服务端处理完数据后，也向客户端发送 FIN 报⽂，之后服务端进⼊ LAST_ACK 状态。
* 客户端收到服务端的 FIN 报⽂后，回⼀个 ACK 应答报⽂，之后进⼊ TIME_WAIT 状态
* 服务器收到了 ACK 应答报⽂后，就进⼊了 CLOSED 状态，⾄此服务端已经完成连接的关闭。
* 客户端在经过 2MSL ⼀段时间后，⾃动进⼊ CLOSED 状态，⾄此客户端也完成连接的关闭。

**为什么挥⼿需要四次？**

* 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。
* 服务器收到客户端的 FIN 报⽂时，先回⼀个 ACK 应答报⽂，⽽服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报⽂给客户端来表示同意现在关闭连接。

从上⾯过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从⽽⽐三次握⼿导致多了⼀次。

#####  **TCP** **重传、滑动窗⼝、流量控制、拥塞控制**

* 重传机制
  * 超时重传
  * 快速重传
  * SACK方法
  * Duplicate SACK

* 滑动窗口：即使在往返时间较⻓的情况下，它也不会降低⽹络通信的效率。通常窗⼝的⼤⼩是由接收⽅的窗⼝⼤⼩来决定的。

  * 发送方的滑动窗口
  * 接收方的滑动窗口

* 流量控制：发送⽅不能⽆脑的发数据给接收⽅，要考虑接收⽅处理能⼒。**TCP** **提供⼀种机制可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量，这就是所谓的流量控制。**

  * **操作系统缓冲区与滑动窗⼝的关系**
    * 当应⽤程序没有及时读取缓存时，发送窗⼝和接收窗⼝的变化。
    * 当服务端系统资源⾮常紧张的时候，操⼼系统可能会直接减少了接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓存数据，那么这时候就有严᯿的事情发⽣了，会出现数据包丢失的现象。--**为了防⽌这种情况发⽣，TCP规定是不允许同时减少缓存⼜收缩窗⼝的，⽽是采⽤先收缩窗⼝，过段时间再减少缓存，这样就可以避免了丢包情况。**

  * 窗口关闭
    * TCP 是如何解决窗⼝关闭时，潜在的死锁现象呢？为了解决这个问题，TCP 为每个连接设有⼀个持续定时器，**只要** **TCP** **连接⼀⽅收到对⽅的零窗⼝通知，就启动持续计时器。**

  * **糊涂窗⼝综合症**：如果接收⽅太忙了，来不及取⾛接收窗⼝⾥的数据，那么就会导致发送⽅的发送窗⼝越来越⼩。到最后，**如果接收⽅腾出⼏个字节并告诉发送⽅现在有⼏个字节的窗⼝，⽽发送⽅会义⽆反顾地发送这⼏个字节，这就是糊涂窗⼝综合症**。
    * 要解决糊涂窗⼝综合症，就解决上⾯两个问题就可以了
      * 让接收⽅不通告⼩窗⼝给发送⽅  -- min( MSS，缓存空间/2 ) 
      * 让发送⽅避免发送⼩数据  --Nagle 算法

* 拥塞控制：在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤**....

  * 什么是拥塞窗⼝？和发送窗⼝有什么关系呢？
    ***拥塞窗⼝** **cwnd**是发送⽅维护的⼀个的状态变ᰁ，它会根据**⽹络的拥塞程度动态变化的**。
  * 我们在前⾯提到过发送窗⼝ swnd 和接收窗⼝ rwnd 是约等于的关系，那么由于加⼊了拥塞窗⼝的概念后，此时发送窗⼝的值是swnd = min(cwnd, rwnd)，也就是拥塞窗⼝和接收窗⼝中的最⼩值。
  * 拥塞窗⼝ cwnd 变化的规则：
    * 只要⽹络中没有出现拥塞， cwnd 就会增⼤；
    * 但⽹络中出现了拥塞， cwnd 就减少

  * 拥塞控制主要的四个算法

    * 慢启动  --**当发送⽅每收到⼀个** **ACK，拥塞窗⼝ cwnd的⼤⼩就会加1**。 --指数增长

    * 拥塞避免 --**每当收到⼀个** **ACK时，cwnd增加 1/cwnd。** --线性增长

    * 拥塞发生 --当发⽣了「超时重传」，则就会使⽤拥塞发⽣算法。

      

      * ssthresh 设为 cwnd/2
      * cwnd 重置为 1或者

      发⽣快速᯿传的拥塞发⽣算法

      * cwnd = cwnd/2 ，也就是设置为原来的⼀半;
      * ssthresh = cwnd ;
      * 进⼊快速恢复算法
        * 拥塞窗⼝ cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；
        * 重传丢失的数据包；
        * 如果再收到᯿复的 ACK，那么 cwnd 增加 1；
        * 如果收到新数据的 ACK 后，把 cwnd 设置为第⼀步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进⼊拥塞避免状态；

    * 拥塞恢复



### 四、IP篇

















